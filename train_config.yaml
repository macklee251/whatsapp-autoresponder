# Configurações do modelo
model_name_or_path: /workspace/qwen2.5-7b-instruct
output_dir: /workspace/whatsapp-autoresponder/output
logging_dir: /workspace/whatsapp-autoresponder/logs

# Configurações de dados
dataset_dir: /workspace/whatsapp-autoresponder/data
dataset: dialogs_style,dialogs_style_with_personality  # Nomes das chaves no dataset_info.json
template: qwen  # Template compatível com Qwen2.5
cutoff_len: 1024  # Comprimento máximo da sequência
train_on_prompt: false
packing: true  # Empacotar múltiplos exemplos

# Configurações de treinamento
num_train_epochs: 3
per_device_train_batch_size: 2  # Ajuste para 1 se houver erro de memória
gradient_accumulation_steps: 4  # Batch efetivo: 8
learning_rate: 2e-5
save_strategy: steps
save_steps: 500
logging_steps: 50
warmup_ratio: 0.03
lr_scheduler_type: cosine
fp16: true  # Precisão mista para otimizar VRAM

# Configurações de LoRA
finetuning_type: lora
lora_rank: 8  # Renomeado de lora_r
lora_alpha: 16
lora_dropout: 0.05
lora_target: all  # Ajustar todos os módulos lineares
max_grad_norm: 1.0  # Clipping de gradientes
weight_decay: 0.01  # Decay para otimização